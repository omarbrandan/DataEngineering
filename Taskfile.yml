version: '3'

env:
  ROOT_PROJECT: ./workspaces/DataEngineering
  DOCKER: ../../docker-compose.yml

tasks:
  pre_project:
    cmds:
      - echo "CREATE THE AIRLFOW AND THE STORAGE DIRS"
      - mkdir -p $ROOT_PROJECT
      - |
        if [ ! -f $ROOT_PROJECT/.env ]; then
          echo "Creating .env file..."
          echo -e "AIRFLOW_UID=$(id -u)" > $ROOT_PROJECT/.env
          cat <<EOF >> $ROOT_PROJECT/.env
        AIRFLOW_GID=0
        REDSHIFT_URL=
        REDSHIFT_USER=
        REDSHIFT_PASSWORD=
        REDSHIFT_PORT=
        REDSHIFT_DBNAME=
        REDSHIFT_SCHEMA=
        REDSHIFT_HOST=
        EMAIL=
        EMAIL_PASSWORD=
        SMTP_HOST=
        SMTP_STARTTLS=
        SMTP_SSL=
        SMTP_USER=
        SMTP_PASSWORD=
        SMTP_PORT=
        SMTP_MAIL_FROM=
        EOF
        else
          echo ".env file already exists"
        fi
      - source $ROOT_PROJECT/.env
      - mkdir -p $ROOT_PROJECT/{raw_data,processed_data,dags,logs,plugins,config}
      - tree -L 2 $ROOT_PROJECT

  install_dependencies:
    cmds:
      - echo "Installing Python dependencies inside the Airflow container"
      - docker compose -f $ROOT_PROJECT/$DOCKER run --rm airflow-webserver bash -c "pip install -r /opt/airflow/requirements.txt"

  start_project:
    deps: [install_dependencies]
    cmds:
      - source $ROOT_PROJECT/.env
      - docker compose -f $ROOT_PROJECT/$DOCKER up airflow-init --build
      - docker compose -f $ROOT_PROJECT/$DOCKER up -d --build
      - docker container ls -a

  down_project:
    cmds:
      - docker compose -f $ROOT_PROJECT/$DOCKER down

  cleanup: 
    cmds:
      - rm -rf  $ROOT_PROJECT/{raw_data,processed_data,logs,plugins,config}
      - rm -f   $ROOT_PROJECT/.env
      - rm -rf  $ROOT_PROJECT/dags/*pycache*
      - rm -rf  $ROOT_PROJECT/dags/*/*pycache*